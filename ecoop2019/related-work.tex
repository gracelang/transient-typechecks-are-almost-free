%!TEX root = paper.tex

\section{Related Work}
\label{sec:related-work}

Although syntaxes for type annotations in dynamic languages go back at
least as far as Lisp\citep{cltl2}, the first attempts at adding a
comprehensive static type system to a dynamically typed
language involved 
Smalltalk\citep{RalphJohnson1986}, with the first practical system
being Bracha's Strongtalk\citep{strongtalk}. Strongtalk
(independently replicated for Ruby\citep{DBRuby09}) provided a
powerful and flexible static type system, where crucially, the system
was \emph{optional} (also known as pluggable
\cite{GiladPluggable2004}). Programmers could run the static checker
over their Smalltalk code (or not); either way the type annotations
had no impact whatsoever of the semantics of the underlying Smalltalk
program.

Siek and Taha~\cite{Siek2006} introduced the term ``gradual typing''
 to describe the logical extension of this scheme: a
dynamic language with type annotations that could, if necessary, be
checked at runtime. Siek and Taha build on earlier complementary work extending fully statically typed languages with a ``\texttt{DYNAMIC}''
type---Abadi~\textit{et~al.}~'s 1991 TOPLAS paper~\cite{AbadiTOPLAS1991} is an
important early attempt
and also surveys previous work.

Revived practical adoption of dynamic languages generated revived
research interest, leading to the formulation of the ``gradual
guarantee''\citep{Siek2006,XXXSiek2015} to characterize sound gradual
type systems: removing type annotations should not change the
semantics of a correct program, drawing on Boyland's critical insight
that, of course, such a guarantee must by its nature forbid code that
can depend on the presence or absence of type declarations elsewhere
in the program\citep{Boyland2014}.
%%%WRONG KJX
%% As Siek et~al.\ explain, by
%% choosing to check only the ``top-most type constructor'', the
%% semantics we present in this paper should meet the refined gradual
%% guarantee \cite{XXXSiek2015}.
Because Moth only checks explicit type declarations (not inferred
intermediate types), Moth cannot not meet the \ugh{refined gradual guarantee}\sm{what's this? reviewer question. James, please tell us what this is}.
Moth ensures only that
the values passing through type annotations cannot be incompatible
with those annotations.

Type errors in gradual, or other dynamically checked, type systems will
often be triggered by the type declarations, but often those
declarations will not be at fault---indeed in a correctly typed
program in a sound gradually typed system,  the declarations cannot be
at fault because they will have passed the static type
checker. Rather, the underlying fault must be somewhere within the
barbarian dynamically typed code \emph{trans vallum}.
Blame tracking\citep{blame2009,blameThreesomes2010,blameForAll2011} localizes these
faults by identifying 
the point in the program where the system makes an 
assumption about dynamically typed objects, so can identify the root
cause should the assumption fail.  Different semantics for blame
detect these faults slightly differently, and impose more or less
implementation
overhead\citep{reticPython2014,monotonic2015,Vitousek2017}.

%\kjx{check following paragraph}
The diversity of semantics and language designs incorporating
gradual typing has been captured recently via surveys
incorporating formal models of different design options.
Chung et~al.\citep{kafka18} present an object-oriented model covering optional
semantics (erasure),  transient semantics, concrete semantics (from Thorn
\cite{Bloom2009}), and behavioural semantics (from Typed Racket), and
give a series of programs to clarify the semantics of a
particular language.  
Greenman et~al.\ take a more functional approach, again modelling
erasure, transient (``first order''), and behavioural (``higher
order'') semantics \cite{bensurvey18icfp}, and also present
performance information based on Typed Racket.
Wilson et~al.\ take a rather different approach, employing
questionnaires to investigate the semantics programmers expect of a
gradual typing system  \cite{shriramdls18}.

As with languages more generally, there seem to be two main implementation
strategies for languages mixing dynamic and static type checks: either
adding static checks into a dynamic language implementation, or adding
support for dynamic types to an implementation that depends on
static types for efficiency. Typed Racket, for example, optimizes code with
a combination of type inference and type declarations---the Racket
IDE ``optimizer coach'' goes as far as to suggest to programmers type
annotations that may improve their program's performance\citep{optimizerCoach2012}. In these implementations, values flowing
from dynamically to statically typed code must be checked at the
boundary.  Fully statically typed code needs no dynamic type checks,
and so generally performs better than dynamically typed code. Adopting
a gradual type system such as Typed Racket\citep{typedScheme08} allows
programmers to explicitly declare types that can be checked statically,
removing unnecessary overhead.

On the other hand, systems such as Reticulated Python\citep{reticPython2014}, SafeTypeScript\citep{Richards2017}, and our
work here, take the opposite approach.
%%KJX might be correct, but next sentence says same thing much better.a
%They add run-time type checks that do not rely on static
%type declarations.
These systems do not use information from type
declarations to optimize execution speed, rather the necessity to
perform (potentially repeated) dynamic type checks tends to slow
programs down, so here code with no type annotations generally
performs better than statically typed code, or rather, code with many
type annotations. In the limit, these kinds of systems may only ever
check types dynamically and may not involve a static type checker at
all. 
%% SM: removed because I still think this isn't correct
%  Several recent languages including HACK \cite{HACK}, Typescript
% \cite{typeScriptECOOP,typeScriptTyping}, Dart \cite{dartbook}, and Grace
% \cite{graceOnward12} follow this general approach.

As gradual typing systems have come to wider attention, the question of their
implementation overheads has become more prominent.  
Takikawa~\textit{et~al.}~\cite{Takikawa2016} asked ``is sound gradual typing
dead?'' based on a systematic performance measurement on Typed Racket.
The key here is their evaluation method, where they constructed a
number of different permutations of typed and untyped code, and
evaluated performance along the spectrum.
Bauman~\textit{et~al.}~\cite{Bauman2017} replied to Takikawa~\textit{et~al.}'s study, in which they used Pycket\citep{Pycket2015} (a tracing JIT for Racket)
rather than the standard Racket VM,
but maintained full gradually-typed Racket semantics.
Bauman~\textit{et~al.} are able to demonstrate most benchmarks
with a slowdown of 2x on average over all configurations.
Note that this is not directly comparable to our system,
since typed modules do not need to do any checks at run time.
Typed Racket only needs to perform checks at boundaries between typed and untyped modules,
however, they use the same essential optimization technique that we apply,
using object shapes to encode information about gradual types.
% - argument about acceptable performance made indirectly
%   using the "CDF-based slowdown plots"
%   - allows choice of arbitrary threshold of what is acceptable overhead
%     - Pycket always better than Racket
%     - not as applicable in our case, because we don't do module-based typing
%   - use Typed Racket's approach to gradual type checking
%   - optimize it by using object shapes, as we do
%     however, because of their more sophisticated semantics,
%     the optimization does only remove part of the overhead
%     specifically, they optimize the number of objects that need to be traversed
%     to perform checks based on their contracts
%     however, they can not reduce it to a simple pointer comparison as in our
%     case, though they get the benefit of more precise checks
Muehlboeck and Tate~\cite{Muehlboeck2017} also replied to
Takikawa~\textit{et~al.}, using a similar benchmarking method applied
to Nom, a language with features designed to make gradual types easier
to optimize, demonstrating speedups as more type information is added
to programs.  Their approach enables such type-driven optimizations,
but relies on a static analysis which can utilize the type
information, and the underlying types are nominal, rather than
structural.


% \rrtodo{Are we nearly equal Greenman,
% in the sense that a reference to a type object the same as a tag?}

Most recently, Kuhlenschmidt~\textit{et~al.}~\cite{Kuhlenschmidt:2018:preprint} employ an
ahead of time (\ie traditional, static) compiler for a custom
language called Grift and demonstrate good performance for code where more than
half of the program is annotated with types, and reasonable
performance for code without type annotations.

\label{reticRW}
Perhaps the closest to our approach are
Vitousek~\textit{et~al.}~\cite{reticPython2014} (incl. \citep{Vitousek2017,Greenman2018})
and Richards~\textit{et~al.}~\cite{Richards2017}.
Vitousek~\textit{et~al.}~describe dynamically checking transient types
% ``tag-type'' soundness
for Reticulated Python (termed ``tag-type'' soundness by Greenman
and Migeed~\cite{Greenman2018}).
As with our work, Vitousek~\textit{et~al.}'s transient checks inspect
only the ``top-level'' type of an
object.
%against a declaration.
%
%KJX arguably wrong. after all, what else do you check types agains
%except a declaration?  Retic do check only the top-level type, but
%they do it whenever the static checker tells them to, including
%implicit intermediate inferred types, but not if the static checker
%says OK. We check only explicit declarations.
%
Reticulated Python undertakes these transient type checks at different
places to Moth.  Moth explicitly checks type annotations, while
Reticulated Python implicitly checks whenever values flow from dynamic
to static types.
%
%\sm{any important difference we need to mention here?}
%\sm{and please make sure this is true!!}
%\mwh{I've checked with both the papers and the implementation. It
%  seems essentially correct and without much meaningful difference.
%  1) Reticulated has an additional static checker, and also
%  statically removes unnecessary checks by a dataflow analysis.
%  The checks are removed to improve performance.
%  2) It does check field values when read, and when assigned to,
%  but only from outside the object. self.x = abc is always
%  unchecked.
%  3) Methods or fields are checked as present by name, but
%  signatures and values are not used until access time (like Moth,
%  except for arity?).
%  4) They do not check the values inside lists (etc) eagerly, but
%  do check when they are retrieved as for other methods (like Moth,
%  I think)
%}
%\kjx{don't think Retic checks return values --- some this is now
%  earlier, check for retricRW refs}
%
% all the above is pretty much correct, but retic actualy checks at
% different places to us.  I don't know who does more, them or us!
% it will depend on the program.  Explicitly typed
% static-single-assignment form Grace code (where every indermediate
% value is named explicitly by a local, and that local is typed)
% would do strictly *more* checks than RP.
% If we have to go around again, that's probably easier than doing an
% higher fidelity model of retic
%
%  although \citeauthor{reticPython2014}'s checks are nominal
% while ours are structural.
% - based on Reticulated Python
% - Python 3-based implementation (interpretation, no compilation)
%- soundness notion and supported semantics very similar to ours
%- evaluate the performance in detail
% - generate different variants to see how the number of type checks correlate
%   with performance
% - we could possibly do the same, but expect similar results and instead
%   focused on identifying more precisely which types of type annotations
%   might relate to performance issues
%   - thus, we only tested N configurations per benchmark\sm{N should be a macro}
We refrain from a direct performance comparison since
Reticulated Python is an interpreter without just-in-time compilation
and thus performance tradeoffs are different.

Richards~\textit{et~al.}~\cite{Richards2017} take a similar implementation
approach to our work, demonstrating that key mechanisms such as object shapes
used by a VM to optimize dynamic languages can be used to eliminate most of
the overhead of dynamic type checks.
Unlike our work, Richards
implement ``monotonic'' gradual typing with blame, rather than
the simpler transient checks, and do so on top of an adapted Higgs
VM.
The Higgs VM implements a baseline just-in-time compiler based on
basic-block versioning\citep{Chevalier-Boisvert:2016:ITS}.
In contrast, our implementation of dynamic checks
is built on top of the Truffle framework for the Graal VM, and reaches
performance approaching that of V8 (cf. \cref{sec:baseline-perf}).
The performance difference is of relevance here since any small constant factors
introduced into a VM with a lower baseline performance can remain hidden,
while they stand out more prominently on a faster baseline.

Overall, it is unclear whether our results confirm the ones
reported by Richards~\textit{et~al.}~\cite{Richards2017},
because our system is simpler.
It does not introduce the polymorphism
issues caused by accumulating cast information on object shapes,
which could be important for performance.
Considering that Richards~\textit{et~al.} report ca. 4\% overhead
on the classic Richards benchmark, while we see \OverheadRichardsP,
further work seems necessary to understand the performance implications of
their approach for a highly optimizing just-in-time compiler.

%- based on Higgs JavaScript VM
%- SafeTypeScript
%  - system of object contracts
%  - checked lazily where possible
%    i.e., when accessing an object (reading, writing fields, method invocations are preceded by field read)
%    for a function object, which may have contracts, before it is invoked
%  - as described in sec. XX, we only check the availability of methods/fields
%    in a type
%    - this has also consequences on checking higher-order functions
%      - we only check whether they take the expected number of arguments,
%        which is part of their type, but don't check types of their arguments
%        (same for normal methods)
%  - optimized by recording the object contracts as part of the shape
%  - this technique is essentially identical to ours
%    - our type information is encoded in the shape, too
%    - however, we check conformance eagerly
%      - this is as part of having semantics for Grace that provide immediate
%        feedback on correctness
%    - from a performance perspective, their approach could have an even higher
%      cost: increased degree of polymorphism (ours is not increased,
%      because we do not use shape trees.
%      each class has a single shape, shared by all instances
%      the type is based on the specified members, which are statically known)
%
%- Higgs
%  - no inlining, escape analysis, tuned GC, etc.
%  - any optimizations across basic blocks (beside type propagation)



