%!TEX root = ../latex/paper.tex

\section{Related Work}
\label{sec:related-work}

Although syntaxes for type annotations in dynamic languages go back at
least as far as Lisp\citep{cltl2}, the first attempts at adding a
comprehensive static type system to a dynamically typed
language involved 
Smalltalk\citep{RalphJohnson1986}, with the first practical system
being Bracha's Strongtalk\citep{strongtalk}. Strongtalk
(independently replicated for Ruby\citep{DBRuby09}) provided a
powerful and flexible static type system, where crucially, the system
was \emph{optional} (also known as pluggable
\cite{GiladPluggable2004}). Programmers could run the static checker
over their Smalltalk code (or not); either way the type annotations
had no impact whatsoever of the semantics of the underlying Smalltalk
program.

\citet{Siek2006} introduced the term ``gradual typing''
 to describe the logical extension of this scheme: a
dynamic language with type annotations that could, if necessary, be
checked at runtime. \citeauthor{Siek2006} build on earlier complementary work extending fully statically typed languages with a ``\texttt{DYNAMIC}''
type---\citet{AbadiTOPLAS1991} is an
important early attempt
and also surveys previous work. Revived practical adoption of dynamic
languages generated revived research interest, leading to the
formulation of the ``gradual guarantee''\citep{Siek2006,Siek2015} to characterize sound
gradual type systems: removing type annotations should not change the
semantics of a correct program, drawing on Boyland's critical
insight that, of course, such a guarantee must by its nature forbid
code that can depend on the presence or absence of type declarations 
elsewhere in the program\citep{Boyland2014}. 

Type errors in gradual, or other dynamically checked, type systems will
often be triggered by the type declarations, but often those
declarations will not be at fault---indeed in a correctly typed
program in a sound gradually typed system,  the declarations cannot be
at fault because they will have passed the static type
checker. Rather, the underlying fault must be somewhere within the
barbarian dynamically typed code \emph{trans vallum}.
Blame tracking\citep{blame2009,blameThreesomes2010,blameForAll2011} localizes these
faults by identifying 
the point in the program where the system makes an 
assumption about dynamically typed objects, so can identify the root
cause should the assumption fail.  Different semantics for blame
detect these faults slightly differently, and impose more or less
implementation overhead\citep{reticPython2014,monotonic2015,Vitousek2017}.

As with language designs, there seem to be two main implementation
strategies for languages mixing dynamic and static type checks: either
adding static checks into a dynamic language implementation, or adding
support for dynamic types to an implementation that depends on
static types for efficiently. Typed Racket, for example, optimizes code with
a combination of type inference and type declarations---the Racket
IDE ``optimizer coach'' goes as far as to suggest to programmers type
annotations that may improve their program's performance\citep{optimizerCoach2012}. In these implementations, values flowing
from dynamically to statically typed code must be checked at the
boundary.  Fully statically typed code needs no dynamic type checks,
and so generally performs better than dynamically typed code. Adopting
a gradual type system such as Typed Racket\citep{typedScheme08} allows
programmers to explicitly declare types that can be checked statically,
removing unnecessary overhead.

On the other hand, systems such as Reticulated Python\citep{reticPython2014}, SafeTypeScript\citep{Richards2017}, and our
work here, takes the opposite approach.
They add run-time type checks that do not rely on static
type declarations. These systems do not use information from type
declarations to optimize execution speed, rather the necessity to
perform (potentially repeated) dynamic type checks tends to slow
programs down, so here code with no type annotations generally
performs better than statically typed code, or rather, code with many
type annotations. In the limit, these kinds of systems may only ever
check types dynamically and may not involve a static type checker at
all. 
%% SM: removed because I still think this isn't correct
%  Several recent languages including HACK \cite{HACK}, Typescript
% \cite{typeScriptECOOP,typeScriptTyping}, Dart \cite{dartbook}, and Grace
% \cite{graceOnward12} follow this general approach.

As these systems have come to wider attention, the question of their
implementation overheads has become more prominent.  
\citet{Takikawa2016} asked ``is sound gradual typing
dead?'' based on a systematic performance measurement on Typed Racket.
The key here is their evaluation method, where they constructed a
number of different permutations of typed and untyped code, and
evaluated performance along the spectrum.
\citet{Bauman2017} replied to \citeauthor{Takikawa2016}'s study, but
using Pycket\citep{Pycket2015}, a tracing JIT for Racket, rather
than the standard Racket VM, although maintaining full gradually typed
Racket semantics. \citeauthor{Bauman2017} are able to demonstrate most benchmarks
with a slowdown of 2x on average over all configurations.
Note that this is not directly comparable to our system,
since typed modules do not need to do any checks at run time.
Typed Racket only needs to perform checks at boundaries between typed and untyped modules,
however, they use the same essential optimization technique that we apply,
using object shapes to encode information about gradual types.
% - argument about acceptable performance made indirectly
%   using the "CDF-based slowdown plots"
%   - allows choice of arbitrary threshold of what is acceptable overhead
%     - Pycket always better than Racket
%     - not as applicable in our case, because we don't do module-based typing
%   - use Typed Racket's approach to gradual type checking
%   - optimize it by using object shapes, as we do
%     however, because of their more sophisticated semantics,
%     the optimization does only remove part of the overhead
%     specifically, they optimize the number of objects that need to be traversed
%     to perform checks based on their contracts
%     however, they can not reduce it to a simple pointer comparison as in our
%     case, though they get the benefit of more precise checks


\citet{Muehlboeck2017} also replied to \citeauthor{Takikawa2016}, 
using a similar benchmarking method applied to Nom, a language
with features designed to make gradual types easier to optimize, 
demonstrating speedups as more type information is added to programs.
Their approach enables such type-driven optimizations,
but relies on a static analysis which can utilize the type information.


% \rrtodo{Are we nearly equal Greenman,
% in the sense that a reference to a type object the same as a tag?}


%% SM: Removed, I can't say anything concrete here.
%%     No idea how to compare to this system.
%%     Their base lines are just too diffent, and I have no how these systems
%%     would perform on our benchmarks.

%%%dumpted in anyway since we cite it, we should say something
%%%even if we are saying nothing
%%%
Most recently, \citet{Kuhlenschmidt:2018:preprint} employ an
ahead of time (\ie traditional, static) compiler for a custom
language called Grift and demonstrate good performance for code where more than
half of the program is annotated with types, and reasonable
performance for code without type annotations. 



Perhaps the closest to our approach are \citet{Greenman2018}
and \citet{Richards2017}.
\citeauthor{Greenman2018} describe dynamically checking ``tag-type''
soundness for Reticulated Python.
As with our work, \citeauthor{Greenman2018} check only the ``top-level'' type of an
object against a declaration, although \citeauthor{Greenman2018}'s checks are nominal
while ours are structural.
% - based on Reticulated Python
  % - Python 3-based implementation (interpretation, no compilation)
%- soundness notion and supported semantics very similar to ours
%- evaluate the performance in detail
% - generate different variants to see how the number of type checks correlate
%   with performance
% - we could possibly do the same, but expect similar results and instead
%   focused on identifying more precisely which types of type annotations
%   might relate to performance issues
%   - thus, we only tested N configurations per benchmark\sm{N should be a macro}
We refrain from a performance comparison since
Reticulated Python is an interpreter without just-in-time compilation
and thus performance tradeoffs are different.

\citet{Richards2017} take a similar implementation
approach to our work, demonstrating that key mechanisms such as object shapes
used by a VM to optimize dynamic languages can be used to eliminate most of
the overhead of dynamic type checks.
Unlike our work, Richards
implement ``full'' gradual typing with blame tracking, rather than
shallow structural checks, and do so on top of an adapted Higgs
VM.
The Higgs VM implements a baseline just-in-time compiler based on
basic-block versioning\citep{Chevalier-Boisvert:2016:ITS}.
In contrast, our implementation of dynamic checks
is built on top of the Truffle framework for the Graal VM, and reaches
performance approaching that of V8 (cf. \cref{sec:baseline-perf}).
The performance difference is of relevance here since any small constant factors
introduces into a VM with a lower baseline performance can remain hidden,
while they stand out more prominently on a faster baseline.

Overall, it is unclear whether our results confirm the ones
reported by \citet{Richards2017},
because our system is simpler.
It does not introduce the polymorphism
issues caused by accumulating cast information on object shapes,
which could be important for performance.
Considering that \citeauthor{Richards2017} report ca. 4\% overhead
on the classic Richards benchmark, while we see \OverheadRichardsP,
further work seems necessary to understand the performance implications of
their approach for a highly optimizing just-in-time compiler.

%- based on Higgs JavaScript VM
%- SafeTypeScript
%  - system of object contracts
%  - checked lazily where possible
%    i.e., when accessing an object (reading, writing fields, method invocations are preceded by field read)
%    for a function object, which may have contracts, before it is invoked
%  - as described in sec. XX, we only check the availability of methods/fields
%    in a type
%    - this has also consequences on checking higher-order functions
%      - we only check whether they take the expected number of arguments,
%        which is part of their type, but don't check types of their arguments
%        (same for normal methods)
%  - optimized by recording the object contracts as part of the shape
%  - this technique is essentially identical to ours
%    - our type information is encoded in the shape, too
%    - however, we check conformance eagerly
%      - this is as part of having semantics for Grace that provide immediate
%        feedback on correctness
%    - from a performance perspective, their approach could have an even higher
%      cost: increased degree of polymorphism (ours is not increased,
%      because we do not use shape trees.
%      each class has a single shape, shared by all instances
%      the type is based on the specified members, which are statically known)
%
%- Higgs
%  - no inlining, escape analysis, tuned GC, etc.
%  - any optimizations across basic blocks (beside type propagation)



